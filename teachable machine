import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from sklearn.preprocessing import LabelEncoder
import json
from pathlib import Path

@dataclass
class DataPoint:
    features: np.ndarray
    label: Any

@dataclass
class ModelConfig:
    input_size: int
    hidden_size: int
    output_size: int
    learning_rate: float = 0.001
    epochs: int = 100

class DynamicNeuralNetwork(nn.Module):
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.layer1 = nn.Linear(config.input_size, config.hidden_size)
        self.layer2 = nn.Linear(config.hidden_size, config.hidden_size)
        self.layer3 = nn.Linear(config.hidden_size, config.output_size)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.dropout(x)
        x = self.relu(self.layer2(x))
        x = self.dropout(x)
        x = self.layer3(x)
        return x

class TeachableMachine:
    def __init__(self):
        self.model = None
        self.config = None
        self.label_encoder = LabelEncoder()
        self.feature_normalizer = None
        self.training_history = []
        
    def preprocess_data(self, data_points: List[DataPoint]) -> Tuple[torch.Tensor, torch.Tensor]:
        """Preprocess data points into tensors."""
        features = np.array([dp.features for dp in data_points])
        labels = np.array([dp.label for dp in data_points])
        
        # Encode labels
        encoded_labels = self.label_encoder.fit
